Following the increasing demand for faster compputation, we will discuss various techniques of the CUDA Runtime and optimizations of memory transfer and access patterns.\\
While CPUs are able to maintain levels of performance, GPUs can achieve higher parallelism due to the parallel concept of graphics processing. Unlike CPUs, graphics units operate at a lower frequency, but have many more cores to make up for it.\\
In order to fully make use of the massive parallelism, we have to apply several techniques like coalescing access to global memory to achieve the highest possible throughput.\\
